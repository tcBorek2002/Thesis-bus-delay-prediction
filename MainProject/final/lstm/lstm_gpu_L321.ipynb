{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6f3ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T11:57:08.435123Z",
     "iopub.status.busy": "2025-12-07T11:57:08.434417Z",
     "iopub.status.idle": "2025-12-07T11:57:08.523985Z",
     "shell.execute_reply": "2025-12-07T11:57:08.523193Z",
     "shell.execute_reply.started": "2025-12-07T11:57:08.435092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Check if GPU is available\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs available:\", gpus)\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # (Optional) set memory growth so TF doesn’t grab all GPU memory at once\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth set for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"⚠️ No GPU detected, running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea792a4-78bd-4286-8b8b-f5e03073cb58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T19:38:27.420491Z",
     "iopub.status.busy": "2025-12-06T19:38:27.420167Z",
     "iopub.status.idle": "2025-12-06T19:38:28.050725Z",
     "shell.execute_reply": "2025-12-06T19:38:28.048725Z",
     "shell.execute_reply.started": "2025-12-06T19:38:27.420452Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Start working with TPU\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local') # Detect TPU\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b8ce8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T12:04:10.081419Z",
     "iopub.status.busy": "2025-12-07T12:04:10.081235Z",
     "iopub.status.idle": "2025-12-07T12:04:12.932958Z",
     "shell.execute_reply": "2025-12-07T12:04:12.932111Z",
     "shell.execute_reply.started": "2025-12-07T12:04:10.081398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load and preprocess data with day_type\n",
    "combinations_df = pd.read_csv(\n",
    "    '../input/line321_combinations_exp.csv',\n",
    "    usecols=[\n",
    "        'to_station',\n",
    "        'current_stop_index',\n",
    "        'current_delay',\n",
    "        'target_stop_index',\n",
    "        'target_delay',\n",
    "        'day_type'\n",
    "    ],\n",
    "    dtype={\n",
    "        'to_station': 'bool',\n",
    "        'current_stop_index': np.int8,\n",
    "        'current_delay': np.float16,\n",
    "        'target_stop_index': np.int8,\n",
    "        'target_delay': np.float16,\n",
    "        'day_type': np.int8\n",
    "    }\n",
    ")\n",
    "\n",
    "X_raw = combinations_df[['to_station', 'current_stop_index', 'current_delay',\n",
    "                         'target_stop_index', 'day_type']]\n",
    "y = combinations_df['target_delay']\n",
    "\n",
    "# Experimental day_type and WEATHER\n",
    "# combinations_df = pd.read_csv('../input/line321_combinations_with_weather.csv', usecols=['to_station', 'current_stop_index', 'current_delay', 'target_stop_index', 'target_delay', 'day_type', 'FR/windspeed (0.1 m/s)', 'TG/temperature (0.1 °C)', 'RH/precipitation (0.1mm)'], dtype={'to_station': 'bool', 'current_stop_index': np.int8, 'current_delay': np.float16, 'target_stop_index': np.int8, 'target_delay': np.float16, 'day_type': np.int8, 'FR/windspeed (0.1 m/s)': np.float16, 'TG/temperature (0.1 °C)': np.float16, 'RH/precipitation (0.1mm)': np.float16})\n",
    "# X_raw = combinations_df[['to_station', 'current_stop_index', 'current_delay', 'target_stop_index', 'day_type', 'FR/windspeed (0.1 m/s)', 'TG/temperature (0.1 °C)', 'RH/precipitation (0.1mm)']]\n",
    "# y = combinations_df['target_delay']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "\n",
    "# Convert to float32 for fast GPU ops\n",
    "X_scaled = X_scaled.astype('float32')\n",
    "y = y.values.astype('float32')\n",
    "\n",
    "# Reshape for LSTM: [samples, timesteps, features]\n",
    "# Each sample = 1 timestep (tabular -> sequence length 1)\n",
    "X = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Train/test split (we'll create a validation split in the next cell)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3a0a3",
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-07T12:06:40.943Z",
     "iopub.execute_input": "2025-12-07T12:04:41.686874Z",
     "iopub.status.busy": "2025-12-07T12:04:41.686287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check GPU\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPUs available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Optional: avoid TF grabbing all GPU memory at once\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Create explicit train/validation split from training data\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "batch_size = 256  # Larger batch to better use the GPU\n",
    "\n",
    "# Build tf.data pipelines for efficient feeding\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_tr, y_tr))\n",
    "    .shuffle(len(X_tr))\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Build LSTM model (cuDNN-friendly settings)\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(\n",
    "        256,                        # a bit larger to benefit from GPU\n",
    "        return_sequences=False,\n",
    "        activation='tanh',\n",
    "        recurrent_activation='sigmoid',\n",
    "        recurrent_dropout=0.0,      # must be 0.0 for cuDNN fast path\n",
    "        unroll=False,\n",
    "        use_bias=True,\n",
    "        unit_forget_bias=True\n",
    "    ),\n",
    "    Dropout(0.2),\n",
    "    Dense(48, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate NRMSE (Normalized RMSE, normalized by the range of y_test)\n",
    "nrmse = rmse / (np.max(y_test) - np.min(y_test))\n",
    "\n",
    "# Calculate SMAPE (Symmetric Mean Absolute Percentage Error)\n",
    "smape = 100 * np.mean(2 * np.abs(y_pred - y_test) / (np.abs(y_test) + np.abs(y_pred) + 1e-8))\n",
    "\n",
    "# Calculate 90th Percentile Absolute Error (P90 AE)\n",
    "p90_ae = np.percentile(np.abs(y_test - y_pred), 90)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Symmetric MAPE (SMAPE): {smape:.2f}%\")\n",
    "print(f\"Normalized RMSE (NRMSE): {nrmse:.4f}\")\n",
    "print(f\"90th Percentile Absolute Error (P90 AE): {p90_ae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b5bfb",
   "metadata": {},
   "source": [
    "## LSTM Hyperparameter Optimization with KerasTuner\n",
    "This cell uses KerasTuner to search for the best LSTM architecture and training parameters to minimize MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ea4ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T13:54:05.126660Z",
     "iopub.status.busy": "2025-12-07T13:54:05.126369Z",
     "iopub.status.idle": "2025-12-07T13:54:05.253360Z",
     "shell.execute_reply": "2025-12-07T13:54:05.252667Z",
     "shell.execute_reply.started": "2025-12-07T13:54:05.126640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure float32 (good for GPU + cuDNN)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "y_train = y_train.astype(\"float32\")\n",
    "\n",
    "# Fixed train/val split used for ALL tuner trials\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "def build_lstm_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "\n",
    "    # 4 choices → 32, 64, 96, 128\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            # units=hp.Choice(\"lstm_units\", [32, 64, 96, 128]),\n",
    "            units=hp.Choice(\"lstm_units\", [32, 64, 96]),\n",
    "            return_sequences=False,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            recurrent_dropout=0.0,   # keep cuDNN fast path\n",
    "            unroll=False,\n",
    "            use_bias=True,\n",
    "            unit_forget_bias=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 5 choices → 0.1, 0.2, 0.3, 0.4, 0.5\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            rate=hp.Choice(\"dropout\", [0.2, 0.3, 0.4])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 4 choices → 16, 32, 48, 64\n",
    "    # model.add(\n",
    "    #     Dense(\n",
    "    #         units=hp.Choice(\"dense_units\", [16, 32, 48, 64]),\n",
    "    #         units=hp.Choice(\"dense_units\", [32]),\n",
    "    #         activation=\"relu\"\n",
    "    #     )\n",
    "    # )\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # 5 choices → total 400 combos\n",
    "    lr = hp.Choice(\n",
    "        \"learning_rate\",\n",
    "        # values=[1e-4, 3e-4, 1e-3, 3e-3, 1e-2]\n",
    "        values=[1e-4, 5e-4, 1e-3]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586f037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:04:19.558098Z",
     "iopub.status.busy": "2025-12-07T14:04:19.557534Z",
     "iopub.status.idle": "2025-12-07T14:04:19.610246Z",
     "shell.execute_reply": "2025-12-07T14:04:19.609560Z",
     "shell.execute_reply.started": "2025-12-07T14:04:19.558074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    hypermodel=build_lstm_model,\n",
    "    objective=\"val_mae\",\n",
    "    max_trials=20,               # number of configurations to try\n",
    "    num_initial_points=5,        # random warmup before it gets \"smart\"\n",
    "    directory=\"./data/lstm_bayes\",\n",
    "    project_name=\"bayes_321\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40854c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:04:22.295268Z",
     "iopub.status.busy": "2025-12-07T14:04:22.294616Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_tr, y_tr,\n",
    "    epochs=18,                # upper bound per trial; EarlyStopping will often stop earlier\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best hyperparameters:\", best_hps.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62fd5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and train the best model\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_model.predict(X_test).flatten()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Tuned LSTM - MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}, R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa4f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example predictions: Glaspoort to Piazza and Evoluon to Piazza\n",
    "X_new = np.zeros((1, 1, X_train.shape[2]))\n",
    "col_idx = {col: i for i, col in enumerate(X_encoded.columns)}\n",
    "X_new[0, 0, col_idx['current_stop_index']] = 13\n",
    "X_new[0, 0, col_idx['current_delay']] = -60\n",
    "X_new[0, 0, col_idx['target_stop_index']] = 15\n",
    "X_new[0, 0, col_idx['to_station']] = 1\n",
    "# Set day_type columns as needed (e.g., X_new[0, 0, col_idx['day_type_Monday']] = 1)\n",
    "y_new_pred = model.predict(X_new).flatten()\n",
    "print(f'Glaspoort to Piazza delay (LSTM): {y_new_pred[0]:.2f}')\n",
    "\n",
    "X_evoluon = np.zeros((1, 1, X_train.shape[2]))\n",
    "X_evoluon[0, 0, col_idx['current_stop_index']] = 10\n",
    "X_evoluon[0, 0, col_idx['current_delay']] = 120\n",
    "X_evoluon[0, 0, col_idx['target_stop_index']] = 15\n",
    "X_evoluon[0, 0, col_idx['to_station']] = 1\n",
    "# Set day_type columns as needed\n",
    "y_evoluon_pred = model.predict(X_evoluon).flatten()\n",
    "print(f'Evoluon to Piazza delay (LSTM): {y_evoluon_pred[0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d123f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('./data/models/lstm_model_L321.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96063641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "best_model.save('./data/models/lstm_model_L321_optimized.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3399ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = tf.keras.models.load_model('./data/models/lstm_model_L321.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28359c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = best_model.predict(X_test).flatten()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8935940,
     "sourceId": 14032666,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
