{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7728d9b",
   "metadata": {},
   "source": [
    "##### Part 1: Generate dataset without weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07377ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "csv_dir = \"../data/converted/\"\n",
    "files = [os.path.join(csv_dir, f) for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
    "last62files = sorted(files)[-62:]\n",
    "\n",
    "cxx_df = pd.concat([pd.read_csv(f, usecols=['messagetype', 'operatingday', 'journeynumber', 'userstopcode', 'punctuality', 'lineplanningnumber'], dtype={'messagetype': 'category', 'operatingday': 'string', 'lineplanningnumber': 'string', 'journeynumber': np.uint16, 'userstopcode': np.int32, 'punctuality': np.float16, 'rd_x': np.float32, 'rd_y': np.float32, 'vehiclenumber': np.float16, 'userstopcode': 'string'}) for f in last62files], ignore_index=True)\n",
    "\n",
    "filtered_df = cxx_df[(cxx_df['lineplanningnumber'] == 'L011') & (cxx_df['messagetype'] == 'DEPARTURE')]\n",
    "print(filtered_df[['journeynumber', 'operatingday']].drop_duplicates().shape[0], 'unique journeys in dataset.')\n",
    "unique_stops_array = filtered_df['userstopcode'].unique()\n",
    "print('Unique stops on line 011:', len(unique_stops_array))\n",
    "amount_of_stops = len(unique_stops_array)\n",
    "\n",
    "to_station = unique_stops_array[:amount_of_stops//2 + 1]\n",
    "to_station_indexes_map = {stop: idx for idx, stop in enumerate(to_station)}\n",
    "from_station = unique_stops_array[amount_of_stops//2:]\n",
    "from_station_indexes_map = {stop: idx for idx, stop in enumerate(from_station)}\n",
    "print('To station indexes map:', to_station_indexes_map)\n",
    "print('From station indexes map:', from_station_indexes_map)\n",
    "\n",
    "# Add day_type column:\n",
    "def get_day_type(date_str):\n",
    "    dt = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    weekday = dt.weekday()\n",
    "    return weekday\n",
    "\n",
    "filtered_df['day_type'] = filtered_df['operatingday'].apply(get_day_type)\n",
    "\n",
    "all_combinations = []\n",
    "all_messages = []\n",
    "# Use both operatingday and journeynumber as unique journey identifier\n",
    "unique_journeys = filtered_df[['operatingday', 'journeynumber']].drop_duplicates()\n",
    "for _, journey_row in unique_journeys.iterrows():\n",
    "    operatingday = journey_row['operatingday']\n",
    "    journeynumber = journey_row['journeynumber']\n",
    "    df_journey = filtered_df[(filtered_df['operatingday'] == operatingday) & (filtered_df['journeynumber'] == journeynumber)]\n",
    "    if df_journey.empty:\n",
    "        continue\n",
    "    rows = []\n",
    "\n",
    "    # Ensure df_journey is ordered by stop sequence (keep your existing sort if you want)\n",
    "    stops_011_order = {stop: idx for idx, stop in enumerate(unique_stops_array)}\n",
    "    df_journey = df_journey.sort_values(by='userstopcode', key=lambda x: x.map(stops_011_order))\n",
    "\n",
    "    # IMPORTANT: make index positional so i/j comparisons follow the sorted order\n",
    "    df_journey = df_journey.reset_index(drop=True)\n",
    "\n",
    "    first_stop = df_journey.iloc[0]['userstopcode']\n",
    "    if first_stop == list(from_station_indexes_map.keys())[0]:\n",
    "        direction = 0 \n",
    "    else:\n",
    "        direction = 1\n",
    "\n",
    "    # NEW: per-journey stop index map (prevents -1 due to missing global keys)\n",
    "    stop_index_map = {}\n",
    "    for pos, stop in enumerate(df_journey['userstopcode'].tolist()):\n",
    "        stop_index_map.setdefault(stop, pos)  # keep first occurrence if duplicates exist\n",
    "\n",
    "    for i, current_row in df_journey.iterrows():\n",
    "        for j, target_row in df_journey.iterrows():\n",
    "            if current_row['userstopcode'] == target_row['userstopcode']:\n",
    "                continue\n",
    "            if j <= i:  # only consider forward combinations (now works as intended)\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                'to_station': direction,\n",
    "                'operatingday': operatingday,\n",
    "                'day_type': current_row['day_type'],\n",
    "                'journeynumber': journeynumber,\n",
    "                'current_stop': current_row['userstopcode'],\n",
    "                'current_stop_index': stop_index_map.get(current_row['userstopcode'], -1),\n",
    "                'current_delay': current_row['punctuality'],\n",
    "                'target_stop_index': stop_index_map.get(target_row['userstopcode'], -1),\n",
    "                'target_stop': target_row['userstopcode'],\n",
    "                'target_delay': target_row['punctuality']\n",
    "            })\n",
    "\n",
    "    combinations_df = pd.DataFrame(rows)\n",
    "    all_combinations.append(combinations_df)\n",
    "    all_messages.append(df_journey)\n",
    "\n",
    "if all_combinations:\n",
    "    final_combinations_df = pd.concat(all_combinations, ignore_index=True)\n",
    "    final_combinations_df.to_csv('./input/line011_combinations_exp.csv', index=False)\n",
    "if all_messages:\n",
    "    final_messages_df = pd.concat(all_messages, ignore_index=True)\n",
    "    final_messages_df.to_csv('./input/line011_messages_exp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b92472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the amount of rows in the final combinations dataframe from csv export\n",
    "import pandas as pd\n",
    "final_combinations_df = pd.read_csv('./input/line011_combinations_exp.csv')\n",
    "print('Total combinations in exported CSV:', final_combinations_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddf138d",
   "metadata": {},
   "source": [
    "##### Part 2.1: Parse/Prepare weather data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae18b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the weather data file\n",
    "df = pd.read_csv('../../ndov-dataset/data/etmgeg_370.txt', skipinitialspace=True)\n",
    "\n",
    "# Select relevant columns\n",
    "weather_df = df[['YYYYMMDD', 'FG', 'TG', 'RH']]\n",
    "\n",
    "# Rename columns for clarity\n",
    "weather_df = weather_df.rename(columns={\n",
    "    'YYYYMMDD': 'date',\n",
    "    'FG': 'FR/windspeed (0.1 m/s)',\n",
    "    'TG': 'TG/temperature (0.1 Â°C)',\n",
    "    'RH': 'RH/precipitation (0.1mm)'\n",
    "})\n",
    "\n",
    "# Convert date column to datetime\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "# Filter for dates between 2025-06-08 and 2025-08-12 (inclusive)\n",
    "start_date = datetime(2025, 6, 8)\n",
    "end_date = datetime(2025, 8, 12)\n",
    "filtered_weather_df = weather_df[(weather_df['date'] >= start_date) & (weather_df['date'] <= end_date)]\n",
    "\n",
    "print(filtered_weather_df.head())\n",
    "filtered_weather_df.to_csv('./input/weather.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of precipitation (RH) in filtered period\n",
    "rh_values = filtered_weather_df['RH/precipitation (0.1mm)']\n",
    "print('RH (precipitation) statistics for selected period:')\n",
    "print('Min:', rh_values.min())\n",
    "print('Max:', rh_values.max())\n",
    "print('Mean:', rh_values.mean())\n",
    "print('Std (spread):', rh_values.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fede6",
   "metadata": {},
   "source": [
    "##### Part 2.2: Generate set with weather features added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83014eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load journey combinations\n",
    "combinations_df = pd.read_csv('./input/line011_combinations_exp.csv')\n",
    "\n",
    "\n",
    "# Load weather data\n",
    "weather_df = pd.read_csv('./input/weather.csv')\n",
    "\n",
    "# Ensure date columns are strings for matching\n",
    "weather_df['date'] = weather_df['date'].astype(str)\n",
    "combinations_df['operatingday'] = combinations_df['operatingday'].astype(str)\n",
    "\n",
    "# Merge weather data into journey data\n",
    "merged_df = combinations_df.merge(\n",
    "    weather_df,\n",
    "    left_on='operatingday',\n",
    "    right_on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the redundant 'date' column\n",
    "merged_df = merged_df.drop(columns=['date'])\n",
    "\n",
    "# Save the merged dataframe\n",
    "merged_df.to_csv('./input/line011_combinations_with_weather.csv', index=False)\n",
    "\n",
    "merged_df.tail(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
