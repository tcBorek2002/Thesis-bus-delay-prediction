{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebb5717",
   "metadata": {},
   "source": [
    "# XGBoost Regressor for Delay Prediction\n",
    "This notebook demonstrates how to use a Gradient Boosting Regressor to predict the delay at a target stop using features such as current stop, current delay, and target stop. It includes data loading, preprocessing, model training, evaluation, and example predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f5411c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd790b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental day_type\n",
    "combinations_df = pd.read_csv('../input/line401_combinations_exp.csv', usecols=['to_station', 'current_stop_index', 'current_delay', 'target_stop_index', 'target_delay', 'day_type'], dtype={'to_station': 'bool', 'current_stop_index': np.int8, 'current_delay': np.float16, 'target_stop_index': np.int8, 'target_delay': np.float16, 'day_type': np.int8})\n",
    "X_raw = combinations_df[['to_station', 'current_stop_index', 'current_delay', 'target_stop_index', 'day_type']]\n",
    "y = combinations_df['target_delay']\n",
    "X_encoded = X_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629f59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental day_type and WEATHER\n",
    "combinations_df = pd.read_csv('../input/line401_combinations_with_weather.csv', usecols=['to_station', 'current_stop_index', 'current_delay', 'target_stop_index', 'target_delay', 'day_type', 'FR/windspeed (0.1 m/s)', 'TG/temperature (0.1 째C)', 'RH/precipitation (0.1mm)'], dtype={'to_station': 'bool', 'current_stop_index': np.int8, 'current_delay': np.float16, 'target_stop_index': np.int8, 'target_delay': np.float16, 'day_type': np.int8, 'FR/windspeed (0.1 m/s)': np.float16, 'TG/temperature (0.1 째C)': np.float16, 'RH/precipitation (0.1mm)': np.float16})\n",
    "X_raw = combinations_df[['to_station', 'current_stop_index', 'current_delay', 'target_stop_index', 'day_type', 'FR/windspeed (0.1 m/s)', 'TG/temperature (0.1 째C)', 'RH/precipitation (0.1mm)']]\n",
    "y = combinations_df['target_delay']\n",
    "X_encoded = X_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data and train model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# model = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "#                          n_estimators=100, random_state=42, learning_rate=0.2, max_depth=6, subsample=1.0, colsample_bytree=1.0)\n",
    "# model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    colsample_bytree=0.8,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=9,\n",
    "    n_estimators=300,\n",
    "    subsample=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b7169",
   "metadata": {},
   "source": [
    "#### Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30818260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model:\n",
    "import joblib\n",
    "joblib.dump(gb, './data/models/gradient_boosting_model_L401.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a19a33",
   "metadata": {},
   "source": [
    "#### Importing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b1a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "gb = joblib.load('./data/models/gradient_boosting_model_L401.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d21b68",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31353820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate NRMSE (Normalized RMSE, normalized by the range of y_test)\n",
    "nrmse = rmse / (np.max(y_test) - np.min(y_test))\n",
    "\n",
    "# Calculate SMAPE (Symmetric Mean Absolute Percentage Error)\n",
    "smape = 100 * np.mean(2 * np.abs(y_pred - y_test) / (np.abs(y_test) + np.abs(y_pred) + 1e-8))\n",
    "\n",
    "# Calculate 90th Percentile Absolute Error (P90 AE)\n",
    "p90_ae = np.percentile(np.abs(y_test - y_pred), 90)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "# print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "# print(f\"Symmetric MAPE (SMAPE): {smape:.2f}%\")\n",
    "print(f\"Normalized RMSE (NRMSE): {nrmse:.4f}\")\n",
    "print(f\"90th Percentile Absolute Error (P90 AE): {p90_ae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809379e6",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4190bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [3, 6, 9],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'subsample': [0.8, 1.0],\n",
    "#     'colsample_bytree': [0.8, 1.0]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 250, 300],\n",
    "    'max_depth': [9, 11, 14],\n",
    "    'learning_rate': [0.2, 0.3, 0.4],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8]\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(\n",
    "    estimator=xgb.XGBRegressor(objective='reg:squarederror', random_state=42),\n",
    "    param_distributions=param_grid, cv=3, n_jobs=-1, verbose=2\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2deb28",
   "metadata": {},
   "source": [
    "#### Feature plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "importance = model.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': list(importance.keys()),\n",
    "    'Importance': list(importance.values())\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_n = 20\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(\n",
    "    importance_df['Feature'].head(top_n)[::-1],\n",
    "    importance_df['Importance'].head(top_n)[::-1],\n",
    "    color='skyblue'\n",
    ")\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title(f'Top {top_n} Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af688684",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d19379",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_tree(model, num_trees=2)\n",
    "xgb.to_graphviz(model, num_trees=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122bb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example predictions: Glaspoort to Piazza and Evoluon to Piazza\n",
    "X_new = pd.DataFrame(0, index=[0], columns=X_train.columns)\n",
    "X_new['current_stop_index'] = 13\n",
    "X_new['current_delay'] = -60\n",
    "X_new['target_stop_index'] = 15\n",
    "X_new['to_station'] = 1\n",
    "y_new_pred = model.predict(X_new)\n",
    "print(f'Glaspoort to Piazza delay (GB): {y_new_pred[0]:.2f}')\n",
    "\n",
    "X_evoluon = pd.DataFrame(0, index=[0], columns=X_train.columns)\n",
    "X_evoluon['current_stop_index'] = 10\n",
    "X_evoluon['current_delay'] = 120\n",
    "X_evoluon['target_stop_index'] = 15\n",
    "X_evoluon['TG/temperature (0.1 째C)'] = 200  # Example temperature\n",
    "X_evoluon['to_station'] = 1\n",
    "y_evoluon_pred = model.predict(X_evoluon)\n",
    "print(f'Evoluon to Piazza delay (GB): {y_evoluon_pred[0]:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
