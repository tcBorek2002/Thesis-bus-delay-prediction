{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7344057",
   "metadata": {},
   "source": [
    "## NDOV Data importing\n",
    "#### This notebook imports data, cleans it and filters it, and saves it to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbcf3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def print_bad_line(bad_line):\n",
    "    print(\"Bad line encountered:\", bad_line)\n",
    "    return None  # skip the bad line\n",
    "\n",
    "names = [\"receive\", \"message\", \"vehicle\", \"messagetype\", \"operatingday\", \"dataownercode\", \"lineplanningnumber\", \"journeynumber\", \"reinforcementnumber\", \"userstopcode\", \"passagesequencenumber\", \"distancesincelastuserstop\", \"punctuality\", \"rd_x\", \"rd_y\", \"blockcode\", \"vehiclenumber\", \"wheelchairaccessible\", \"source\", \"numberofcoaches\"]\n",
    "dirp = Path('/run/media/borek/KINGSTON/ndov/kv6') # directory path\n",
    "files = [p for p in dirp.iterdir() if p.is_file() and p.name.endswith('.log')]  # only .log files\n",
    "files_sorted = sorted(files, key=lambda p: p.name)  # Sort files by name\n",
    "\n",
    "# Load stops to keep (ZOB region)\n",
    "stops_df = pd.read_csv('./data/stops.csv')\n",
    "stops_to_keep = stops_df['UserStopCode'].astype(str).tolist()\n",
    "\n",
    "# Message types to keep\n",
    "message_types = ['DEPARTURE', 'ARRIVAL']\n",
    "\n",
    "# Output directory for cleaned files\n",
    "output_dir = Path('./data/converted')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "dropColumns = ['dataownercode', 'reinforcementnumber', 'passagesequencenumber', 'distancesincelastuserstop', 'blockcode', 'wheelchairaccessible', 'source', 'numberofcoaches']\n",
    "\n",
    "# Detect already processed files\n",
    "processed_files = set([f.name for f in output_dir.glob('*_cleaned.csv')])\n",
    "\n",
    "total_files = len(files_sorted)\n",
    "\n",
    "print(' Starting file processing loop')\n",
    "for idx, file in enumerate(files_sorted, 1):\n",
    "    out_filename = f'{file.stem}_cleaned.csv'\n",
    "    if out_filename in processed_files:\n",
    "        continue\n",
    "    start_time = time.time()\n",
    "    print(f'Processing {file.name} ({idx}/{total_files})')\n",
    "    df = pd.read_csv(file, sep=';', names=names, dtype={'userstopcode': 'string'}, encoding_errors='replace', on_bad_lines='warn')\n",
    "    filtered = df[df['dataownercode'] == 'CXX']\n",
    "    filtered = filtered[filtered['messagetype'].isin(message_types)]\n",
    "    filtered = filtered[filtered['userstopcode'].astype(str).isin(stops_to_keep)]\n",
    "    filtered = filtered.drop(columns=dropColumns)\n",
    "    filtered = filtered.reset_index(drop=True)\n",
    "    # Save to CSV\n",
    "    out_path = output_dir / out_filename\n",
    "    filtered.to_csv(out_path, index=False)\n",
    "    elapsed = time.time() - start_time\n",
    "    percent = (idx / total_files) * 100\n",
    "    print(f'Saved {out_path} | {percent:.1f}% complete | {elapsed:.2f} seconds')\n",
    "\n",
    "print('Finished file processing loop')\n",
    "# Optionally, preview the first processed file\n",
    "if files_sorted:\n",
    "    preview_df = pd.read_csv(output_dir / f'{files_sorted[0].stem}_cleaned.csv')\n",
    "    preview_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d19ae4",
   "metadata": {},
   "source": [
    "#### Get the userstopcodes for the ZOB region    \n",
    "This should only be run if the stops have not been extracted to a csv file yet from the original NeTEx xml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d55e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_stop_assignments(xml_file, csv_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Get the namespace from the root tag\n",
    "    ns = {'ns': root.tag.split('}')[0].strip('{')}\n",
    "\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['StopName', 'UserStopCode'])\n",
    "\n",
    "        for psa in root.findall('.//ns:PassengerStopAssignment', ns):\n",
    "            name = psa.findtext('ns:Name', namespaces=ns)\n",
    "            quay_ref_elem = psa.find('ns:QuayRef', ns)\n",
    "            quay_ref = quay_ref_elem.get('ref') if quay_ref_elem is not None else ''\n",
    "            # Improved extraction: find last colon and check if the part after is digits\n",
    "            if ':' in quay_ref:\n",
    "                last_part = quay_ref.split(':')[-1]\n",
    "                if last_part.isdigit():\n",
    "                    quay_ref_filtered = last_part\n",
    "                else:\n",
    "                    quay_ref_filtered = quay_ref\n",
    "            else:\n",
    "                quay_ref_filtered = quay_ref\n",
    "            writer.writerow([name, quay_ref_filtered])\n",
    "\n",
    "# Usage:\n",
    "extract_stop_assignments('../data/NeTEx_CXX_SRE_20250917_2025-09-21_202500022_baseline.xml', './data/stops.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9178b1ca",
   "metadata": {},
   "source": [
    "#### Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message types to keep\n",
    "message_types = ['DEPARTURE', 'ARRIVAL']\n",
    "\n",
    "# Stops to keep (ZOB region)\n",
    "stops_df = pd.read_csv('./data/stops.csv')\n",
    "stops_to_keep = stops_df['UserStopCode'].astype(str).tolist()\n",
    "\n",
    "# Filter for dataownercode == 'CXX', messagetype in message_types and userstopcode in stops_to_keep\n",
    "filtered = main_df[main_df['dataownercode'] == 'CXX']\n",
    "filtered = filtered[filtered['messagetype'].isin(message_types)]\n",
    "filtered = filtered[filtered['userstopcode'].astype(str).isin(stops_to_keep)]\n",
    "\n",
    "# Print version before dropping columns\n",
    "filtered.info()\n",
    "\n",
    "# Drop columns not needed\n",
    "# Some columns are always null like distancesincelastuserstop, blockcode, wheelchairaccessible and numberofcoaches\n",
    "# Passagesequencenumber is always 0.0, so we can drop it as well\n",
    "# Other are not relevant for our analysis\n",
    "dropColumns = ['dataownercode', 'reinforcementnumber', 'passagesequencenumber', 'distancesincelastuserstop', 'blockcode', 'wheelchairaccessible', 'source', 'numberofcoaches']\n",
    "filtered = filtered.drop(columns=dropColumns)\n",
    "\n",
    "# Reset index after filtering\n",
    "filtered = filtered.reset_index(drop=True)\n",
    "\n",
    "print(filtered['userstopcode'].apply(type).value_counts())\n",
    "\n",
    "\n",
    "# Save to CSV and show a preview\n",
    "filtered.to_csv('./data/cxx_messages.csv', index=False)\n",
    "filtered.head(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
